                raise ValueError("Vector store nÃ£o foi construÃ­do. Execute build_vectorstore() primeiro.")

            # Busca por similaridade
            results = self.vectorstore.similarity_search(query, k=top_k)

            return results

        except Exception as e:
            print(f"âŒ Erro na busca: {str(e)}")
            raise

    def generate_answer(self, query: str, context_docs: List[Document]) -> str:
        """Gera resposta usando Ollama baseado no contexto recuperado E histÃ³rico de conversa"""
        try:
            # Formata contexto dos documentos
            context = "\n\n---\n\n".join([
                f"[Fonte: {doc.metadata.get('source', 'Desconhecida')}]\n{doc.page_content}"
                for doc in context_docs
            ])

            # ğŸ†• ObtÃ©m histÃ³rico de conversa
            conversation_history = self.memory.get_formatted_history()

            # ğŸ†• NOVO: Prompt melhorado com detecÃ§Ã£o de mudanÃ§a de contexto
            user_prompt = f"""=== HISTÃ“RICO DA CONVERSA ===
{conversation_history}

=== CONTEXTO DOS DOCUMENTOS ===
{context}

=== INSTRUÃ‡Ã•ES CRÃTICAS ===
1. **DETECÃ‡ÃƒO DE MUDANÃ‡A DE ASSUNTO:**
   - Se a pergunta atual NÃƒO se relaciona com o histÃ³rico (ex: muda completamente de tema), IGNORE o histÃ³rico e responda APENAS com base nos documentos.
   - Exemplo: Se o histÃ³rico fala sobre "UBS" e a pergunta Ã© sobre "casa de cachorro", a pergunta NÃƒO tem relaÃ§Ã£o, entÃ£o ignore o histÃ³rico.

2. **USO DO HISTÃ“RICO:**
   - Use o histÃ³rico APENAS quando a pergunta se refere explicitamente a algo mencionado antes (palavras como "isso", "elas", "aquilo", "o que vocÃª disse").
   - Exemplo: "Quais sÃ£o os horÃ¡rios delas?" â†’ "delas" se refere a algo do histÃ³rico.

3. **PRIORIDADE:**
   - SEMPRE responda com base nos DOCUMENTOS, nÃ£o em inferÃªncias.
   - Se a informaÃ§Ã£o NÃƒO estÃ¡ nos documentos, diga claramente: "NÃ£o encontrei essa informaÃ§Ã£o nos documentos."
   - NUNCA invente informaÃ§Ãµes ou repita respostas anteriores se nÃ£o forem relevantes.

4. **CLAREZA:**
   - Seja direto e conciso.
   - NÃ£o repita informaÃ§Ãµes jÃ¡ ditas a menos que seja solicitado.

=== PERGUNTA ATUAL ===
{query}

Responda de forma objetiva baseando-se APENAS nas informaÃ§Ãµes dos documentos."""

            # Chama Ollama
            answer = OllamaManager.generate_response(
                model=self.model_name,
                prompt=user_prompt,
                system_prompt=RAGConfig.SYSTEM_PROMPT,
                temperature=0.3  # Baixa temperatura para respostas mais precisas
            )

            # ğŸ†• Adiciona interaÃ§Ã£o Ã  memÃ³ria
            self.memory.add_interaction(query, answer)

            return answer

        except Exception as e:
            return f"Erro ao gerar resposta: {str(e)}"

    def clear_memory(self) -> None:
        """Limpa o histÃ³rico de conversas"""
        self.memory.clear()

    def show_memory(self) -> None:
        """Exibe o histÃ³rico atual de conversas"""
        print("\n" + "="*70)
        print("ğŸ§  MEMÃ“RIA CONVERSACIONAL")
        print("="*70)
        print(f"Turnos armazenados: {self.memory.get_turn_count()}/{self.memory.max_turns}")
        print("\n" + self.memory.get_formatted_history())
        print("="*70 + "\n")

    def is_query_related_to_history(self, query: str) -> bool:
        """
        Verifica se a pergunta se relaciona com o histÃ³rico recente

        Args:
            query: Pergunta atual

        Returns:
            True se relacionada, False caso contrÃ¡rio
        """
        if not self.memory.history:
            return False

        # Palavras que indicam referÃªncia ao histÃ³rico
        reference_words = [
            'isso', 'aquilo', 'elas', 'eles', 'dela', 'dele', 'delas', 'deles',
            'anterior', 'antes', 'vocÃª disse', 'mencionou', 'falou', 'citou'
        ]

        query_lower = query.lower()

        # Se a pergunta contÃ©m palavras de referÃªncia, Ã© relacionada
        if any(word in query_lower for word in reference_words):
            return True

        # Se a pergunta tem mais de 10 palavras e nÃ£o tem referÃªncias, provavelmente Ã© nova
        if len(query.split()) > 10:
            return False

        # Para perguntas curtas, assume que pode ser relacionada
        return True

    def query(self, question: str, show_context: bool = False, auto_clear_memory: bool = False) -> str:
        """
        MÃ©todo principal: faz pergunta e retorna resposta

        Args:
            question: Pergunta do usuÃ¡rio
            show_context: Se True, mostra o contexto recuperado
            auto_clear_memory: Se True, limpa memÃ³ria ao detectar mudanÃ§a de assunto
        """
        try:
            print(f"\nâ“ Pergunta: {question}\n")

            # ğŸ†• NOVO: Detecta se Ã© uma mudanÃ§a de assunto
            if auto_clear_memory and not self.is_query_related_to_history(question):
                if self.memory.get_turn_count() > 0:
                    print("ğŸ”„ MudanÃ§a de assunto detectada. Limpando memÃ³ria anterior...\n")
                    self.memory.clear()

            # Recupera contexto
            print("ğŸ” Buscando informaÃ§Ãµes relevantes...")
            context_docs = self.retrieve_context(question)

            if show_context:
                print("\nğŸ“š Contexto recuperado:")
                for i, doc in enumerate(context_docs, 1):
                    print(f"\n--- Chunk {i} ---")
                    print(f"Fonte: {doc.metadata.get('source', 'Desconhecida')}")
                    print(f"ConteÃºdo: {doc.page_content[:200]}...")

            # Gera resposta
            print(f"\nğŸ’­ Gerando resposta com {self.model_name}...")
            answer = self.generate_answer(question, context_docs)

            print("\nâœ… Resposta gerada!\n")
            return answer

        except Exception as e:
            error_msg = f"Erro ao processar pergunta: {str(e)}"
            print(f"\nâŒ {error_msg}\n")
            return error_msg